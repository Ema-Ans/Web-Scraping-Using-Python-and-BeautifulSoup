{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d680ffc9-5b33-4ce9-9a23-749b91d87a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to request the data from the web servers\n",
    "import requests as r\n",
    "#works with a parser, to extract data from HTML \n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ecfb7e-e00c-49fc-b158-b62eb4fc32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to load the webpage content from the url\n",
    "webpag = r.get(\"https://attack.mitre.org/groups/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a5ecce-c3be-4975-8a18-bef776c39210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to beautifulsoup\n",
    "soup = bs(webpag.content,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07eb0c72-ffef-49db-bc40-896c47d563f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thead>\n",
       "<tr>\n",
       "<th scope=\"col\">ID</th>\n",
       "<th scope=\"col\">Name</th>\n",
       "<th scope=\"col\">Associated Groups</th>\n",
       "<th scope=\"col\">Description</th>\n",
       "</tr>\n",
       "</thead>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tableHead = soup.thead\n",
    "#tableHead  (if u want to get the tablehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925cb94e-063b-42bd-8031-0fc795e53ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Name', 'Associated Groups', 'Description']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if u want to extract the rowHeaders from the table head\n",
    "# rowHeaders = []\n",
    "# for x in tableHead.find_all('tr'):\n",
    "#     for y in x.find_all('th'):\n",
    "#         rowHeaders.append(y.text)\n",
    "# rowHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d04e25a2-0947-4610-b599-3cc6eb504104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Name', 'Associated Groups', 'Description']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CODE JUNK -  FOR MY FUTURE REF\n",
    "# urlS = []\n",
    "# tableBody = soup.tbody\n",
    "#THIS IS HOW YOU CAN GET ALL THE LINKS FROM A Table.body\n",
    "# urls_list = tableBody.find_all('a')\n",
    "# print(urls_list)\n",
    "# for link in urls_list:\n",
    "#     href = link.get('href')\n",
    "#     urls.append(href)\n",
    "# urls2 = set(urls)\n",
    "# urls2List = list(urls2)\n",
    "# firstelem = urls2List[0]\n",
    "# newUrls = []\n",
    "# for elem in urls2List:\n",
    "#     if elem[:6] == '/group':\n",
    "#         newUrls.append(elem)\n",
    "#newUrls is the finalList of my Urls.\n",
    "#newUrls\n",
    "\n",
    "### CODE STARTS FROM HERE ###\n",
    "table1 = soup.find('table',{'class': \"table table-bordered table-alternate mt-2\"})\n",
    "\n",
    "#if you want to find the headers in the table\n",
    "# headers = []\n",
    "# for i in table1.find_all('th'):\n",
    "#     title = i.text\n",
    "#     headers.append(title)\n",
    "# headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b367b0f8-beab-49bd-89c2-207be2a8763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/groups/G0018\n"
     ]
    }
   ],
   "source": [
    "tableValues = []\n",
    "for x in table1.find_all('tr')[1:]:\n",
    "    #convert it to sets, to get rid of the duplicates\n",
    "    #because the same name is referenced multiple times \n",
    "    td_tags = list(set(x.find_all('a')))\n",
    "    td_val = [y for y in td_tags]\n",
    "    tableValues.append(td_val)\n",
    "#contains [[<a href=\"/software/S0012\">PoisonIvy</a, <a href=\"/groups/G0018\"> G0018 </a>,..] ...] for each row\n",
    "tableValues\n",
    "\n",
    "nameList = []\n",
    "#from that raw html list, we extract the names i.e., texts only for each group\n",
    "for elem in tableValues:\n",
    "    my_val = [y.text for y in elem]\n",
    "    nameList.append(list(set(my_val)))\n",
    "\n",
    "#for each of the elem in html list, we extract its link\n",
    "url_List = []\n",
    "for elem in tableValues:\n",
    "    my_urls = [x.get('href') for x in elem]\n",
    "    url_List.append(list(set(my_urls)))\n",
    "\n",
    "#only want names with ID's i.e., G****\n",
    "clean_nameList = []\n",
    "for x in nameList:\n",
    "    for y in x:\n",
    "        if y[1:3] ==  \"G0\" or y[1:3] == \"G1\":\n",
    "            clean_nameList.append(y)\n",
    "\n",
    "\n",
    "\n",
    "#only want the links for the ID's G****\n",
    "clean_urlList = []\n",
    "for i in range(len(url_List)):\n",
    "    elem = url_List[i]\n",
    "    name = newList[i][1:-1]\n",
    "    for x in elem:\n",
    "        if x[-5:] == name:\n",
    "            clean_urlList.append(x)\n",
    "            \n",
    "#now zip the two lists\n",
    "final_list = list(zip(clean_nameList, clean_urlList))\n",
    "print(final_list[0][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "95668cf5-6b28-47f1-8601-b4dc098c583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.001',\n",
       "  'LOWBALL',\n",
       "  'Account Discovery',\n",
       "  'Local Account',\n",
       "  '[1]',\n",
       "  'T1087',\n",
       "  'admin@338'],\n",
       " ['.003',\n",
       "  'LOWBALL',\n",
       "  'Windows Command Shell',\n",
       "  'T1059',\n",
       "  '[1]',\n",
       "  'Command and Scripting Interpreter',\n",
       "  'admin@338'],\n",
       " ['Exploitation for Client Execution', 'T1203', 'admin@338', '[1]'],\n",
       " ['LOWBALL', 'File and Directory Discovery', '[1]', 'T1083', 'admin@338'],\n",
       " ['Match Legitimate Name or Location',\n",
       "  '[1]',\n",
       "  'Masquerading',\n",
       "  'T1036',\n",
       "  '.005',\n",
       "  'admin@338'],\n",
       " ['.001',\n",
       "  'LOWBALL',\n",
       "  'Permission Groups Discovery',\n",
       "  '[1]',\n",
       "  'admin@338',\n",
       "  'Local Groups',\n",
       "  'T1069'],\n",
       " ['Phishing', '.001', '[1]', 'T1566', 'Spearphishing Attachment', 'admin@338'],\n",
       " ['LOWBALL', 'T1082', '[1]', 'System Information Discovery', 'admin@338'],\n",
       " ['LOWBALL',\n",
       "  'T1016',\n",
       "  '[1]',\n",
       "  'System Network Configuration Discovery',\n",
       "  'admin@338'],\n",
       " ['LOWBALL',\n",
       "  '[1]',\n",
       "  'T1049',\n",
       "  'System Network Connections Discovery',\n",
       "  'admin@338'],\n",
       " ['System Service Discovery', 'LOWBALL', 'T1007', '[1]', 'admin@338'],\n",
       " ['T1204', 'User Execution', '[1]', 'Malicious File', '.002', 'admin@338']]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now create the new_webpage thing using the urls collected from above:\n",
    "link = \"https://attack.mitre.org\" + final_list[0][1] + \"/\"\n",
    "#to load the webpage content from the url\n",
    "webpag1 = r.get(link)\n",
    "#convert to beautifulsoup\n",
    "soup = bs(webpag1.content,\"html.parser\")\n",
    "### CODE STARTS FROM HERE ###\n",
    "table_techniques = soup.find('table',{'class': \"table techniques-used background table-bordered\"})\n",
    "tableValues = []\n",
    "for x in table_techniques.find_all('tr')[1:]:\n",
    "    #convert it to sets, to get rid of the duplicates\n",
    "    #because the same name is referenced multiple times \n",
    "    td_tags = list(set(x.find_all('a')))\n",
    "    td_val = [y for y in td_tags]\n",
    "    tableValues.append(td_val)\n",
    "#contains [[<a href=\"/software/S0012\">PoisonIvy</a, <a href=\"/groups/G0018\"> G0018 </a>,..] ...] for each row\n",
    "tableValues\n",
    "\n",
    "nameList = []\n",
    "#from that raw html list, we extract the names i.e., texts only for each group\n",
    "for elem in tableValues:\n",
    "    my_val = [y.text for y in elem]\n",
    "    nameList.append(list(set(my_val)))\n",
    "nameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f9546-ba53-4317-8660-6020a3465e46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
